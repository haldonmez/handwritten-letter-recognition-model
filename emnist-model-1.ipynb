{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from scipy.ndimage import rotate\n",
    "import time\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a custom dataset\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # Load the data\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the data for one example\n",
    "        example_data = self.data.iloc[index]\n",
    "        # Separate the features from the target\n",
    "        features = torch.tensor(example_data[2:].values, dtype=torch.float32).reshape(1, 28, 28)\n",
    "        target = torch.tensor(example_data.iloc[1], dtype=torch.long)\n",
    "        return features, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def classes(self, index):\n",
    "        return self.data.iloc[index].iloc[1]\n",
    "\n",
    "\n",
    "# Create instances of the dataset\n",
    "train_data = CSVDataset('final_dataset/train_dataset.csv')\n",
    "test_data = CSVDataset('final_dataset/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, torch.Size([1, 28, 28]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[1134]\n",
    "label.item(), image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list = set()\n",
    "for i in range(len(test_data)):\n",
    "    _, target = test_data[i]\n",
    "    classes_list.add(target.item())\n",
    "\n",
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data there is 23057 iterations with the batch size of 16.\n",
      "For testing data there is 3901 iterations with the batch size of 16.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_data, #Dataset to iterate on for the according batch size.\n",
    "                              batch_size = BATCH_SIZE, #Size of every single iteration.\n",
    "                              shuffle = True, #To make the loaded data selected randomly.\n",
    "                              )\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size = BATCH_SIZE,\n",
    "                             shuffle = True)\n",
    "\n",
    "print(f\"For training data there is {len(train_dataloader)} iterations with the batch size of {BATCH_SIZE}.\")\n",
    "print(f\"For testing data there is {len(test_dataloader)} iterations with the batch size of {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LetterRecognizerModel1(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(10, 10, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (bn3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.4, inplace=False)\n",
       "  (conv4): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(20, 20, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (bn6): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.4, inplace=False)\n",
       "  (conv7): Conv2d(20, 40, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn7): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=40, out_features=62, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LetterRecognizerModel1(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_shape, hidden_units, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_units)\n",
    "        self.conv2 = nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_units)\n",
    "        self.conv3 = nn.Conv2d(hidden_units, hidden_units, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_units)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(hidden_units, hidden_units*2, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.conv5 = nn.Conv2d(hidden_units*2, hidden_units*2, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.conv6 = nn.Conv2d(hidden_units*2, hidden_units*2, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn6 = nn.BatchNorm2d(hidden_units*2)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(hidden_units*2, hidden_units*4, kernel_size=4)\n",
    "        self.bn7 = nn.BatchNorm2d(hidden_units*4)\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "        self.fc = nn.Linear(hidden_units*4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.softmax(self.fc(x), dim=1)\n",
    "        return x\n",
    "torch.manual_seed(42)\n",
    "model_1 = LetterRecognizerModel1(input_shape=1,\n",
    "    hidden_units=10,\n",
    "    output_size=len(classes_list)).to(device)\n",
    "model_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
